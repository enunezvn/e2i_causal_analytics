# Inter-Agent Communication Patterns
# Version: 1.0
# Last Updated: 2025-12-18
# Purpose: Define cross-tier and peer-to-peer agent communication patterns

# ==============================================================================
# OVERVIEW
# ==============================================================================

communication_overview:
  version: "1.0"
  description: "Patterns for direct agent-to-agent communication and cross-tier data flow"

  communication_modes:
    - orchestrated: "Primary mode - orchestrator mediates all communication"
    - direct: "Direct agent-to-agent for specific use cases"
    - shared_state: "Communication via shared LangGraph state"
    - memory: "Communication via memory systems"
    - rag: "Communication via RAG indexes"
    - events: "Event-driven communication for async workflows"

  design_principles:
    - "Orchestrator-mediated by default"
    - "Direct communication only when necessary"
    - "Immutable handoffs (agents don't modify upstream results)"
    - "Explicit dependencies in execution graph"
    - "Memory and RAG for cross-session communication"

# ==============================================================================
# TIER 0 ↔ TIER 1-5 INTEGRATION PATTERNS
# ==============================================================================

tier0_integration:
  description: "How ML Foundation (Tier 0) integrates with Causal Analytics (Tier 1-5)"

  # Tier 0 → Tier 1-5 data flow
  tier0_to_upper_tiers:

    # Data Preparer → Drift Monitor
    data_preparer_to_drift_monitor:
      source_agent: data_preparer
      target_agent: drift_monitor
      data_shared:
        - baseline_metrics
        - feature_distributions
        - training_set_statistics
      storage_location: database.baseline_metrics
      access_pattern: pull
      example:
        baseline_metrics:
          experiment_id: "exp_abc123"
          split_type: "train"
          target_rate: 0.34
          feature_stats:
            call_frequency:
              mean: 4.2
              std: 2.1

    # Model Trainer → Prediction Synthesizer
    model_trainer_to_prediction_synthesizer:
      source_agent: model_trainer
      target_agent: prediction_synthesizer
      data_shared:
        - model_id
        - model_uri
        - model_metadata
        - validation_metrics
      storage_location: mlflow.model_registry
      access_pattern: pull
      example:
        model_info:
          model_id: "model_exp_abc123_v1"
          mlflow_run_id: "mlflow_run_xyz789"
          model_uri: "runs:/mlflow_run_xyz789/model"
          registered_model_name: "e2i-kisqali-conversion"
          version: 1

    # Feature Analyzer → Causal Impact
    feature_analyzer_to_causal_impact:
      source_agent: feature_analyzer
      target_agent: causal_impact
      data_shared:
        - feature_importance
        - feature_interactions
        - shap_values
      storage_location: memory.semantic
      access_pattern: pull
      example:
        feature_relationships:
          - features: [call_frequency, territory_potential]
            interaction_strength: 0.15
            interpretation: "Call frequency more effective in high-potential territories"

    # Model Deployer → Prediction Synthesizer
    model_deployer_to_prediction_synthesizer:
      source_agent: model_deployer
      target_agent: prediction_synthesizer
      data_shared:
        - endpoint_url
        - model_version
        - deployment_status
      storage_location: database.deployed_models
      access_pattern: pull
      example:
        deployment_info:
          model_id: "model_exp_abc123_v1"
          endpoint_url: "https://api.example.com/predict/conversion"
          bento_tag: "e2i-conversion-v1"
          deployed_at: "2025-12-18T10:00:00Z"

    # Observability Connector → Health Score
    observability_connector_to_health_score:
      source_agent: observability_connector
      target_agent: health_score
      data_shared:
        - traces
        - metrics
        - errors
        - latencies
      storage_location: opik.traces
      access_pattern: push_and_pull
      example:
        observability_data:
          component: "causal_impact"
          avg_latency_ms: 12000
          p99_latency_ms: 18000
          error_rate: 0.02
          request_count: 450

  # Upper Tiers → Tier 0 triggers
  upper_tiers_to_tier0:

    # Drift Monitor → Model Trainer (retrain trigger)
    drift_monitor_triggers_retraining:
      trigger_agent: drift_monitor
      target_agent: model_trainer
      trigger_condition: "data_drift_severity == 'high' AND model_performance_degraded"
      communication_mode: event
      event_type: model_retrain_requested
      payload:
        model_id: "model_exp_abc123_v1"
        reason: "data_drift"
        urgency: "high"
        drift_features: ["call_frequency", "territory_potential"]

    # Health Score → Observability Connector (alert trigger)
    health_score_triggers_alert:
      trigger_agent: health_score
      target_agent: observability_connector
      trigger_condition: "overall_health_score < 0.7"
      communication_mode: event
      event_type: system_health_alert
      payload:
        severity: "warning"
        health_score: 0.65
        affected_components: ["data_pipeline", "ml_models"]

# ==============================================================================
# TIER 2-5 PEER COMMUNICATION
# ==============================================================================

peer_communication:
  description: "Direct peer-to-peer communication within and across tiers"

  # Tier 2: Causal agents
  tier2_peers:

    # Causal Impact → Gap Analyzer (sequential handoff)
    causal_impact_to_gap_analyzer:
      communication_mode: shared_state
      handoff_format: yaml  # See agent-handoff.yaml
      data_shared:
        - causal_effect_estimate
        - causal_paths
        - refutation_results
      dependency_type: sequential
      example:
        handoff:
          agent: causal_impact
          status: completed
          confidence: 0.85
          outputs:
            effect_estimate:
              ate: 0.18
              confidence_interval: [0.12, 0.24]
          context_for_next_agent:
            causal_effect_confirmed: true
            effect_size: 0.18

    # Causal Impact → Heterogeneous Optimizer (conditional)
    causal_impact_to_heterogeneous_optimizer:
      communication_mode: shared_state
      handoff_format: yaml
      data_shared:
        - cate_detected
        - segment_definitions
        - confounders
      dependency_type: conditional
      dispatch_condition: "cate_detected == true OR entities.segments exists"
      example:
        handoff:
          agent: causal_impact
          outputs:
            cate_detected: true
            suggested_modifiers: ["hcp_volume", "practice_type"]

  # Tier 3: Monitoring agents
  tier3_peers:

    # Drift Monitor → Health Score (parallel, independent)
    drift_monitor_and_health_score:
      communication_mode: independent
      handoff_format: none
      data_shared: []
      dependency_type: none
      note: "Both agents operate independently and don't share data directly"

    # Experiment Designer → Causal Impact (validation)
    experiment_designer_to_causal_impact:
      communication_mode: shared_state
      handoff_format: yaml
      data_shared:
        - experimental_design
        - power_analysis
        - causal_dag
      dependency_type: validation
      purpose: "Causal Impact can validate experimental design assumptions"
      example:
        handoff:
          agent: experiment_designer
          outputs:
            causal_dag_spec:
              treatment: "enhanced_targeting"
              outcome: "NRx"
              confounders: ["hcp_volume", "territory_potential"]

  # Tier 4: Prediction agents
  tier4_peers:

    # Prediction Synthesizer → Resource Optimizer (sequential)
    prediction_synthesizer_to_resource_optimizer:
      communication_mode: shared_state
      handoff_format: yaml
      data_shared:
        - predictions
        - prediction_confidence
        - expected_outcomes
      dependency_type: sequential
      example:
        handoff:
          agent: prediction_synthesizer
          outputs:
            predictions:
              entity_id: "hcp_12345"
              conversion_probability: 0.68
              expected_roi: 3.2

  # Tier 5: Self-improvement agents
  tier5_peers:

    # Explainer → Feedback Learner (async)
    explainer_to_feedback_learner:
      communication_mode: memory_episodic
      handoff_format: none
      data_shared:
        - explanation_id
        - user_feedback
        - effectiveness_metrics
      dependency_type: async
      storage: memory.episodic
      note: "Feedback Learner reads episodic memory asynchronously"
      example:
        episodic_memory_entry:
          event_type: "explanation_generated"
          explanation_id: "expl_abc123"
          query: "What caused the drop in NRx?"
          explanation: "..."
          user_feedback: "helpful"
          timestamp: "2025-12-18T10:30:00Z"

# ==============================================================================
# CROSS-TIER DEPENDENCIES
# ==============================================================================

cross_tier_dependencies:
  description: "Dependencies that span multiple tiers"

  # Tier 0 → Tier 2 dependency chain
  tier0_to_tier2:
    dependency_chain:
      - agent: model_trainer
        provides: trained_model
        tier: 0

      - agent: feature_analyzer
        depends_on: trained_model
        provides: feature_relationships
        tier: 0

      - agent: causal_impact
        depends_on: feature_relationships
        uses_for: confounder_selection
        tier: 2

    access_pattern: pull_from_memory
    memory_type: semantic

  # Tier 0 → Tier 3 dependency chain
  tier0_to_tier3:
    dependency_chain:
      - agent: data_preparer
        provides: baseline_metrics
        tier: 0

      - agent: drift_monitor
        depends_on: baseline_metrics
        uses_for: drift_detection
        tier: 3

    access_pattern: pull_from_database
    storage: database.baseline_metrics

  # Tier 0 → Tier 4 dependency chain
  tier0_to_tier4:
    dependency_chain:
      - agent: model_deployer
        provides: model_endpoint
        tier: 0

      - agent: prediction_synthesizer
        depends_on: model_endpoint
        uses_for: model_inference
        tier: 4

    access_pattern: pull_from_database
    storage: database.deployed_models

  # Tier 2 → Tier 5 dependency chain
  tier2_to_tier5:
    dependency_chain:
      - agent: causal_impact
        provides: analysis_results
        tier: 2

      - agent: gap_analyzer
        provides: opportunities
        tier: 2

      - agent: explainer
        depends_on: [analysis_results, opportunities]
        uses_for: narrative_generation
        tier: 5

    access_pattern: shared_state
    handoff_format: yaml

# ==============================================================================
# SHARED RESOURCE ACCESS PATTERNS
# ==============================================================================

shared_resources:
  description: "Patterns for accessing shared resources"

  # RAG access
  rag_access:
    description: "How agents access RAG indexes"

    # Agents that write to RAG
    rag_writers:
      - agent: causal_impact
        writes_to: [causal_paths, agent_activities]
        write_mode: append
        example:
          causal_paths_entry:
            path: ["enhanced_targeting", "hcp_engagement", "NRx"]
            effect_size: 0.18
            confidence: 0.85
            timestamp: "2025-12-18T10:00:00Z"

      - agent: feedback_learner
        writes_to: [agent_activities]
        write_mode: append
        example:
          agent_activities_entry:
            agent: "feedback_learner"
            activity_type: "rag_weight_adjustment"
            adjustments:
              graph_retrieval_weight: 0.25
            timestamp: "2025-12-18T11:00:00Z"

    # Agents that read from RAG
    rag_readers:
      - agent: causal_impact
        reads_from: [causal_paths, business_metrics]
        read_mode: hybrid_retrieval
        top_k: 5

      - agent: gap_analyzer
        reads_from: [business_metrics, agent_activities]
        read_mode: dense_retrieval
        top_k: 10

      - agent: explainer
        reads_from: [conversations, causal_paths, agent_activities]
        read_mode: hybrid_retrieval
        top_k: 5

  # Memory access
  memory_access:
    description: "How agents access memory systems"

    # Working memory (session-scoped)
    working_memory:
      scope: session
      storage: redis
      ttl_seconds: 3600
      agents_using:
        - orchestrator: "Maintains conversation state"
        - explainer: "Maintains explanation context"
        - feedback_learner: "Maintains batch processing state"

    # Episodic memory (historical queries)
    episodic_memory:
      scope: global
      storage: vector_db
      retention: permanent
      agents_using:
        - explainer: "Retrieves similar past queries"
        - feedback_learner: "Learns from historical feedback"
        - orchestrator: "Suggests related queries"

    # Procedural memory (successful patterns)
    procedural_memory:
      scope: global
      storage: vector_db
      retention: permanent
      agents_using:
        - orchestrator: "Recalls successful agent combinations"
        - feedback_learner: "Identifies effective patterns"

    # Semantic memory (knowledge graph)
    semantic_memory:
      scope: global
      storage: neo4j
      retention: permanent
      agents_using:
        - feature_analyzer: "Stores feature relationships"
        - causal_impact: "Queries causal relationships"
        - gap_analyzer: "Queries business relationships"

  # Database access
  database_access:
    description: "How agents access database"

    # Read-only agents
    read_only:
      - causal_impact: "Reads transactional data for causal analysis"
      - gap_analyzer: "Reads performance metrics"
      - drift_monitor: "Reads feature distributions"
      - health_score: "Reads system metrics"
      - prediction_synthesizer: "Reads entity features"

    # Read-write agents
    read_write:
      - data_preparer: "Writes baseline metrics"
      - model_trainer: "Writes model metadata"
      - model_deployer: "Writes deployment info"
      - observability_connector: "Writes traces and metrics"
      - feedback_learner: "Writes learned patterns"

    # Isolation level
    isolation_level: read_committed
    connection_pooling: true
    max_connections: 50

# ==============================================================================
# EVENT-DRIVEN COMMUNICATION
# ==============================================================================

event_driven:
  description: "Event-driven patterns for async communication"

  # Event bus configuration
  event_bus:
    enabled: true
    implementation: redis_pubsub
    channels:
      - model_events
      - drift_events
      - health_events
      - feedback_events

  # Event types
  event_types:

    # Model retrain requested
    model_retrain_requested:
      publisher: drift_monitor
      subscribers: [model_trainer]
      payload:
        model_id: string
        reason: string  # "data_drift" | "concept_drift" | "performance_degradation"
        urgency: string  # "low" | "medium" | "high"
        metadata: object
      example:
        event: model_retrain_requested
        payload:
          model_id: "model_exp_abc123_v1"
          reason: "data_drift"
          urgency: "high"
          metadata:
            drift_features: ["call_frequency"]
            psi_scores: {call_frequency: 0.28}

    # Model deployed
    model_deployed:
      publisher: model_deployer
      subscribers: [health_score, drift_monitor, prediction_synthesizer]
      payload:
        model_id: string
        endpoint_url: string
        version: int
        deployment_type: string  # "staging" | "production"
      example:
        event: model_deployed
        payload:
          model_id: "model_exp_abc123_v1"
          endpoint_url: "https://api.example.com/predict/conversion"
          version: 1
          deployment_type: "production"

    # Drift detected
    drift_detected:
      publisher: drift_monitor
      subscribers: [health_score, model_trainer, orchestrator]
      payload:
        drift_type: string  # "data_drift" | "concept_drift"
        severity: string  # "low" | "moderate" | "high"
        features_affected: array
        recommended_action: string
      example:
        event: drift_detected
        payload:
          drift_type: "data_drift"
          severity: "high"
          features_affected: ["call_frequency", "territory_potential"]
          recommended_action: "retrain_model"

    # System health degraded
    system_health_degraded:
      publisher: health_score
      subscribers: [orchestrator, observability_connector]
      payload:
        health_score: float
        affected_components: array
        severity: string  # "warning" | "critical"
      example:
        event: system_health_degraded
        payload:
          health_score: 0.65
          affected_components: ["data_pipeline", "ml_models"]
          severity: "warning"

    # Feedback received
    feedback_received:
      publisher: explainer
      subscribers: [feedback_learner]
      payload:
        query_id: string
        explanation_id: string
        feedback_type: string  # "positive" | "negative" | "neutral"
        feedback_text: string
        user_id: string
      example:
        event: feedback_received
        payload:
          query_id: "qry_abc123"
          explanation_id: "expl_xyz789"
          feedback_type: "positive"
          feedback_text: "Very helpful analysis"
          user_id: "user_123"

  # Event handling
  event_handling:
    retry_policy:
      max_retries: 3
      backoff_multiplier: 2.0
      max_backoff_seconds: 60

    dead_letter_queue:
      enabled: true
      retention_days: 7

    ordering:
      guarantee: best_effort
      note: "Events may arrive out of order"

# ==============================================================================
# COMMUNICATION VALIDATION RULES
# ==============================================================================

validation_rules:
  description: "Rules for validating inter-agent communication"

  # Handoff validation
  handoff_validation:
    - rule: "Handoff follows agent-handoff.yaml schema"
      severity: critical

    - rule: "All required fields present (agent, status, confidence, key_findings)"
      severity: critical

    - rule: "Status is valid (completed, partial, failed)"
      severity: critical

    - rule: "Confidence is in range [0.0, 1.0]"
      severity: critical

    - rule: "Key findings list has 1-5 items"
      severity: high

  # State mutation rules
  state_mutation:
    - rule: "Agents CANNOT modify upstream_results"
      severity: critical
      enforcement: immutable_field

    - rule: "Agents CANNOT modify other agents' results"
      severity: critical
      enforcement: namespace_isolation

    - rule: "Agents append to errors/warnings lists only"
      severity: critical
      enforcement: append_only

  # Memory access rules
  memory_access_rules:
    - rule: "Working memory only accessible within same session"
      severity: critical

    - rule: "Episodic memory writes require event_type classification"
      severity: high

    - rule: "Semantic memory writes must include relationships"
      severity: high

  # Database access rules
  database_access_rules:
    - rule: "Use parameterized queries only (no string interpolation)"
      severity: critical

    - rule: "Read-only agents cannot execute write queries"
      severity: critical
      enforcement: connection_permissions

    - rule: "Transactions must complete within 30 seconds"
      severity: high

# ==============================================================================
# DEBUGGING AND OBSERVABILITY
# ==============================================================================

debugging:
  description: "Tools for debugging inter-agent communication"

  # Trace communication paths
  trace_visualization:
    enabled: true
    tool: opik
    features:
      - agent_dependency_graph
      - communication_flow_diagram
      - timing_waterfall
      - error_propagation_trace

  # Communication logging
  logging:
    log_all_handoffs: true
    log_level: INFO
    include_payloads: true
    max_payload_size_kb: 100
    redact_sensitive_fields: true

  # Metrics
  metrics:
    - handoff_count_by_agent_pair
    - average_handoff_size_bytes
    - handoff_validation_failures
    - memory_access_count_by_agent
    - rag_access_count_by_agent
    - event_publish_count_by_type
    - event_processing_latency

# ==============================================================================
# EXAMPLES
# ==============================================================================

examples:
  description: "Common inter-agent communication patterns"

  # Example 1: Sequential Tier 2 flow
  sequential_tier2_flow:
    flow:
      - agent: causal_impact
        action: execute
        output: handoff_yaml

      - agent: gap_analyzer
        action: receive_handoff
        input: causal_impact.handoff
        output: handoff_yaml

      - agent: explainer
        action: receive_multiple_handoffs
        input: [causal_impact.handoff, gap_analyzer.handoff]
        output: final_response

  # Example 2: Tier 0 ML pipeline
  tier0_ml_pipeline:
    flow:
      - agent: scope_definer
        action: execute
        output: scope_spec

      - agent: data_preparer
        action: receive_scope_spec
        input: scope_definer.scope_spec
        gate: qc_gate
        output: data_readiness + baseline_metrics
        writes_to: database.baseline_metrics

      - agent: model_trainer
        action: train_model
        input: data_preparer.data_readiness
        output: trained_model
        writes_to: mlflow.model_registry

      - agent: prediction_synthesizer
        action: load_model
        reads_from: mlflow.model_registry
        uses: trained_model

  # Example 3: Async feedback learning
  async_feedback_learning:
    flow:
      - agent: explainer
        action: generate_explanation
        output: explanation
        writes_to: memory.episodic

      - user: provides_feedback
        action: submit_feedback
        writes_to: memory.episodic

      - agent: feedback_learner
        action: batch_process
        reads_from: memory.episodic
        schedule: daily
        output: learned_patterns
        writes_to: memory.procedural + rag.agent_activities

# ==============================================================================
# END OF INTER-AGENT COMMUNICATION PATTERNS
# ==============================================================================
