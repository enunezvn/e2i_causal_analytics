# E2I Query Processing Flow - Granular Data Handoff Diagram

## Overview

This document provides a granular breakdown of the query processing flow in the E2I Causal Analytics V4.1 system, mapping:
- **Data Handoffs**: What data moves between components
- **Processing Steps**: What transformation happens at each node
- **End States**: How results populate the dashboard

---

## Complete Flow Sequence

```mermaid
sequenceDiagram
    autonumber
    participant U as ğŸ‘¤ User<br/>(Dashboard Chat)
    participant QP as ğŸ”¤ Query Processor<br/>(Layer 1: NLP)
    participant IC as ğŸ¯ Intent Classifier
    participant EE as ğŸ“¦ Entity Extractor
    participant O as ğŸ›ï¸ Orchestrator<br/>(Tier 1)
    participant R as ğŸ”€ Router
    participant T0 as ğŸ¤– Tier 0 Agents<br/>(ML Foundation)
    participant T2 as ğŸ“Š Tier 2 Agents<br/>(Causal Analytics)
    participant CE as âš¡ Causal Engine<br/>(Layer 2)
    participant RAG as ğŸ” CausalRAG
    participant DB as ğŸ—„ï¸ Database<br/>(28 tables)
    participant SYN as ğŸ”— Synthesizer
    participant VER as âœ… Verification
    participant VIZ as ğŸ“ˆ Viz Selector
    participant DASH as ğŸ–¥ï¸ Dashboard

    Note over U,DASH: === PHASE 1: QUERY INGESTION ===

    U->>QP: Raw NL query string<br/>"Why did Kisqali trigger acceptance drop in Q3?"
    
    QP->>QP: Clean & normalize text
    
    par Intent Classification
        QP->>IC: Cleaned query
        IC->>IC: Classify into 5 types:<br/>CAUSAL|GAP|DRIFT|ML_SCOPE|VALIDATION
        IC-->>QP: IntentType.CAUSAL
    and Entity Extraction
        QP->>EE: Cleaned query
        EE->>EE: Fuzzy match against<br/>domain_vocabulary.yaml
        Note right of EE: NO medical NER!<br/>Only: brands, regions,<br/>KPIs, time_periods
        EE-->>QP: ExtractedEntities{<br/>brand: "Kisqali",<br/>metric: "trigger_acceptance",<br/>time: "Q3"}
    end
    
    QP->>QP: Build ParsedQuery object
    
    Note over U,DASH: === PHASE 2: ORCHESTRATION ===
    
    QP->>O: ParsedQuery{intent, entities, query}
    O->>R: Route by tier priority
    R->>R: Map intent â†’ agent(s)
    Note right of R: Lower tier = higher priority<br/>Tier 0 > Tier 1 > ... > Tier 5
    
    R-->>O: AgentPlan[causal_impact,<br/>gap_analyzer, drift_monitor]
    
    O->>O: Multi-step execution plan
    
    Note over U,DASH: === PHASE 3: AGENT EXECUTION ===
    
    alt ML Query (needs Tier 0)
        O->>T0: ML_SCOPE intent
        T0->>T0: scope_definer â†’ data_preparer
        
        rect rgb(236, 72, 153, 0.1)
            Note over T0: ğŸš¦ QC GATE CHECK
            T0->>T0: Great Expectations validation
            alt QC Pass
                T0->>T0: model_selector â†’ model_trainer
                T0->>T0: feature_analyzer (SHAP)
                T0-->>SYN: MLResult + SHAP values
            else QC Fail
                T0-->>O: status="blocked"
            end
        end
    end
    
    O->>T2: CAUSAL intent dispatch
    
    par Causal Impact Agent (5-node workflow)
        T2->>CE: Variables + constraints
        CE->>CE: 1ï¸âƒ£ DAG Builder (NetworkX)
        CE->>DB: Check expert_reviews
        DB-->>CE: DAG approval status
        CE->>CE: 2ï¸âƒ£ Effect Estimator (DoWhy)
        CE->>CE: ATE/CATE calculation
        
        rect rgb(239, 68, 68, 0.1)
            Note over CE: ğŸš¦ REFUTATION GATE
            CE->>CE: 3ï¸âƒ£ RefutationRunner.run_suite()
            Note right of CE: 5 tests:<br/>â€¢ placebo_treatment<br/>â€¢ random_common_cause<br/>â€¢ data_subset<br/>â€¢ bootstrap<br/>â€¢ sensitivity_e_value
            CE->>DB: INSERT causal_validations
            CE->>CE: 4ï¸âƒ£ Sensitivity analysis
            alt gate_decision = "proceed"
                CE->>CE: 5ï¸âƒ£ Interpretation
                CE-->>T2: CausalResult + RefutationSuite
            else gate_decision = "block"
                CE-->>T2: BLOCKED + reasons
            end
        end
        T2-->>SYN: CausalImpactOutput
        
    and RAG Context Retrieval
        T2->>RAG: Query + entities
        RAG->>RAG: Hybrid retrieval:<br/>dense + sparse + graph
        RAG->>DB: Query indexed tables
        Note right of RAG: Sources:<br/>â€¢ causal_paths<br/>â€¢ agent_activities<br/>â€¢ business_metrics<br/>â€¢ causal_validations (V4.1)
        RAG->>RAG: Cross-encoder rerank
        RAG-->>T2: Retrieved context chunks
        
    and Gap Analyzer
        T2->>T2: gap_analyzer
        T2->>DB: Query business_metrics
        T2-->>SYN: GapAnalysis{gaps, ROI}
        
    and Monitoring Agents (Tier 3)
        T2->>T2: drift_monitor
        T2->>DB: Query ml_predictions
        T2-->>SYN: DriftReport{PSI, alerts}
    end
    
    Note over U,DASH: === PHASE 4: SYNTHESIS ===
    
    SYN->>SYN: Merge multi-agent outputs
    SYN->>SYN: Deduplicate insights
    SYN->>SYN: Rank by confidence
    
    SYN->>VER: MergedResponse
    VER->>VER: Confidence scoring
    VER->>VER: Compliance check
    VER->>VER: Hallucination detection
    VER->>DB: Log agent_activities
    
    VER->>VIZ: VerifiedResponse
    VIZ->>VIZ: Rules-based chart selection
    Note right of VIZ: visualization_rules.yaml:<br/>causal â†’ DAG + waterfall<br/>comparison â†’ bar + heatmap<br/>trend â†’ line + area
    
    Note over U,DASH: === PHASE 5: DASHBOARD POPULATION ===
    
    par Chat Response
        VIZ->>DASH: Streaming text + badges
        Note right of DASH: Agent badges show<br/>tier colors
    and Causal DAG
        VIZ->>DASH: DAGSpec{nodes, edges}
        DASH->>DASH: D3.js rendering
    and KPI Cards
        VIZ->>DASH: KPIData[46 metrics]
        DASH->>DASH: Render with causal insights
    and CATE Heatmap
        VIZ->>DASH: CATEMatrix{segments, effects}
        DASH->>DASH: Plotly heatmap
    and Validation Badge
        VIZ->>DASH: RefutationSuite
        Note right of DASH: V4.1: Shows<br/>proceed/review/block
    end
    
    DASH-->>U: Complete response with visualizations
```

---

## Data Handoff Reference Table

| Step | From | To | Data Object | Key Fields |
|------|------|-----|-------------|------------|
| 1 | User | Query Processor | `string` | Raw NL query |
| 2 | Query Processor | Intent Classifier | `CleanedQuery` | normalized_text, tokens |
| 3 | Query Processor | Entity Extractor | `CleanedQuery` | normalized_text, tokens |
| 4 | Intent Classifier | Query Processor | `IntentType` | enum: CAUSAL\|GAP\|DRIFT\|ML_SCOPE\|VALIDATION |
| 5 | Entity Extractor | Query Processor | `ExtractedEntities` | brands[], regions[], kpis[], time_periods[] |
| 6 | Query Processor | Orchestrator | `ParsedQuery` | intent, entities, rewritten_query, confidence |
| 7 | Router | Orchestrator | `AgentPlan` | agents[], priority_order, execution_mode |
| 8 | Orchestrator | Tier 0 Agents | `MLRequest` | scope, constraints, data_requirements |
| 9 | Data Preparer | Model Trainer | `QCResult` | status: pass\|block, failures[], baseline_metrics |
| 10 | Orchestrator | Tier 2 Agents | `CausalRequest` | variables, treatment, outcome, confounders |
| 11 | Causal Engine | Database | `ValidationRecord` | estimate_id, test_type, status, gate_decision |
| 12 | CausalRAG | Agents | `RetrievedContext` | chunks[], sources[], relevance_scores[] |
| 13 | All Agents | Synthesizer | `AgentOutput` | result_type, content, confidence, visualizations[] |
| 14 | Synthesizer | Verification | `MergedResponse` | insights[], conflicts[], citations[] |
| 15 | Verification | Viz Selector | `VerifiedResponse` | content, compliance_status, confidence_score |
| 16 | Viz Selector | Dashboard | `ChatResponse` | text, agent_badges[], stream_tokens |
| 17 | Viz Selector | Dashboard | `DAGSpec` | nodes[], edges[], layout_hints |
| 18 | Viz Selector | Dashboard | `KPIData` | metric_id, value, trend, causal_insight |
| 19 | Viz Selector | Dashboard | `CATEMatrix` | segments[], time_periods[], effects[][] |
| 20 | Viz Selector | Dashboard | `ValidationBadge` | gate_decision, test_results[], confidence_score |

---

## Processing Step Details

### Layer 1: NLP Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QUERY PROCESSOR                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: "Why did Kisqali trigger acceptance drop in Q3?"        â”‚
â”‚                                                                  â”‚
â”‚  Step 1: Normalization                                          â”‚
â”‚    â†’ lowercase, remove punctuation, expand contractions         â”‚
â”‚                                                                  â”‚
â”‚  Step 2: Intent Classification (5 types)                        â”‚
â”‚    â†’ Pattern: "why did X" + metric change = CAUSAL              â”‚
â”‚    â†’ Output: IntentType.CAUSAL                                  â”‚
â”‚                                                                  â”‚
â”‚  Step 3: Entity Extraction (domain_vocabulary.yaml)             â”‚
â”‚    â†’ "Kisqali" fuzzy match â†’ brand: "Kisqali" (score: 1.0)      â”‚
â”‚    â†’ "trigger acceptance" â†’ metric: "trigger_acceptance"         â”‚
â”‚    â†’ "Q3" â†’ time_period: "2024-Q3"                              â”‚
â”‚                                                                  â”‚
â”‚  Step 4: Query Rewriting (for RAG optimization)                 â”‚
â”‚    â†’ "causal factors trigger acceptance decline Kisqali Q3"     â”‚
â”‚                                                                  â”‚
â”‚  Output: ParsedQuery{                                           â”‚
â”‚    intent: CAUSAL,                                              â”‚
â”‚    entities: {brand, metric, time},                             â”‚
â”‚    rewritten: "causal factors...",                              â”‚
â”‚    confidence: 0.92                                             â”‚
â”‚  }                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 2: Causal Engine (5-Node Workflow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CAUSAL IMPACT AGENT WORKFLOW                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Node 1: GraphBuilder                                           â”‚
â”‚    â†’ Input: variables from ParsedQuery                          â”‚
â”‚    â†’ Process: NetworkX DAG construction                         â”‚
â”‚    â†’ Check: expert_reviews table for DAG approval               â”‚
â”‚    â†’ Output: CausalGraph{nodes, edges, confounders}             â”‚
â”‚                                                                  â”‚
â”‚  Node 2: Estimation                                             â”‚
â”‚    â†’ Input: CausalGraph + treatment + outcome                   â”‚
â”‚    â†’ Process: DoWhy/EconML effect estimation                    â”‚
â”‚    â†’ Output: EffectEstimate{ATE, CI, p_value}                   â”‚
â”‚                                                                  â”‚
â”‚  Node 3: Refutation (V4.1) ğŸš¦ GATE                              â”‚
â”‚    â†’ Input: EffectEstimate                                      â”‚
â”‚    â†’ Process: RefutationRunner.run_suite()                      â”‚
â”‚      â”œâ”€â”€ placebo_treatment test                                 â”‚
â”‚      â”œâ”€â”€ random_common_cause test                               â”‚
â”‚      â”œâ”€â”€ data_subset test                                       â”‚
â”‚      â”œâ”€â”€ bootstrap test                                         â”‚
â”‚      â””â”€â”€ sensitivity_e_value test                               â”‚
â”‚    â†’ Persist: INSERT INTO causal_validations                    â”‚
â”‚    â†’ Output: RefutationSuite{tests[], gate_decision}            â”‚
â”‚    â†’ Gate: if gate_decision == "block" â†’ STOP                   â”‚
â”‚                                                                  â”‚
â”‚  Node 4: Sensitivity                                            â”‚
â”‚    â†’ Input: EffectEstimate + RefutationSuite                    â”‚
â”‚    â†’ Process: Sensitivity analysis for unobserved confounders   â”‚
â”‚    â†’ Output: SensitivityResult{e_value, robustness_score}       â”‚
â”‚                                                                  â”‚
â”‚  Node 5: Interpretation                                         â”‚
â”‚    â†’ Input: All previous outputs                                â”‚
â”‚    â†’ Process: LLM-based narrative generation                    â”‚
â”‚    â†’ Output: CausalResult{effect, explanation, confidence}      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dashboard End States

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DASHBOARD COMPONENTS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  1. Chat Response Panel                                         â”‚
â”‚     â”œâ”€â”€ Streaming text (WebSocket)                              â”‚
â”‚     â”œâ”€â”€ Agent badges (tier-colored)                             â”‚
â”‚     â””â”€â”€ Inline citations to sources                             â”‚
â”‚                                                                  â”‚
â”‚  2. Causal DAG Visualization (D3.js)                            â”‚
â”‚     â”œâ”€â”€ Nodes: variables (treatment, outcome, confounders)      â”‚
â”‚     â”œâ”€â”€ Edges: causal relationships with strength               â”‚
â”‚     â””â”€â”€ Interactive: click to see effect details                â”‚
â”‚                                                                  â”‚
â”‚  3. KPI Cards (46 metrics)                                      â”‚
â”‚     â”œâ”€â”€ Value + trend indicator                                 â”‚
â”‚     â”œâ”€â”€ Sparkline chart (Chart.js)                              â”‚
â”‚     â””â”€â”€ Causal insight badge ("â†‘ caused by X")                  â”‚
â”‚                                                                  â”‚
â”‚  4. CATE Heatmap (Plotly)                                       â”‚
â”‚     â”œâ”€â”€ X-axis: Time periods                                    â”‚
â”‚     â”œâ”€â”€ Y-axis: HCP segments                                    â”‚
â”‚     â””â”€â”€ Color: Treatment effect magnitude                       â”‚
â”‚                                                                  â”‚
â”‚  5. Resource Allocation Sankey (Plotly)                         â”‚
â”‚     â”œâ”€â”€ Left: Current budget allocation                         â”‚
â”‚     â”œâ”€â”€ Right: Optimal allocation                               â”‚
â”‚     â””â”€â”€ Flows: Budget movement recommendations                  â”‚
â”‚                                                                  â”‚
â”‚  6. Validation Badge (V4.1)                                     â”‚
â”‚     â”œâ”€â”€ Status: proceed | review | block                        â”‚
â”‚     â”œâ”€â”€ Tests passed: 4/5 âœ“                                     â”‚
â”‚     â””â”€â”€ Confidence score: 87%                                   â”‚
â”‚                                                                  â”‚
â”‚  7. Health Radar Chart (Plotly)                                 â”‚
â”‚     â”œâ”€â”€ 8 dimensions: coverage, AUC, fairness, etc.             â”‚
â”‚     â”œâ”€â”€ Current state (solid)                                   â”‚
â”‚     â””â”€â”€ Target state (dashed)                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Critical Flow Constraints

| Constraint | Location | Behavior |
|------------|----------|----------|
| **NO Medical NER** | Entity Extractor | Only extracts from domain_vocabulary.yaml. Never uses scispaCy, BioBERT. |
| **QC Gate Blocking** | Data Preparer â†’ Model Trainer | Training blocked with status="blocked" if Great Expectations validation fails. |
| **Refutation Required** | Causal Engine Node 3 | All causal effects must pass 5 DoWhy tests. Results persisted to causal_validations. |
| **ML Split Enforcement** | All data access | Same patient always in same split. Test/holdout never exposed in production. |
| **Operational Data Only** | RAG Retrieval | Only indexes: causal_paths, agent_activities, business_metrics, triggers. Never: clinical trials, medical literature. |
| **Tier Priority** | Router | Lower tier = higher priority. Tier 0 requests handled before Tier 5. |

---

## New in V4.1: Validation Infrastructure

### New Tables
- `causal_validations`: Stores refutation test results with gate decisions
- `expert_reviews`: Tracks DAG approval by domain experts

### New ENUMs
- `refutation_test_types`: placebo_treatment, random_common_cause, data_subset, bootstrap, sensitivity_e_value
- `validation_statuses`: passed, failed, warning, skipped
- `gate_decisions`: proceed, review, block

### New Dashboard Component
- **Validation Badge**: Shows refutation status with proceed/review/block indicator and confidence score

---

*Generated from E2I Causal Analytics V4.1 Architecture Documentation*
