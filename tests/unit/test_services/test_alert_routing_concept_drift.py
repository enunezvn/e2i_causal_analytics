"""Unit Tests for Concept Drift Alert Routing.

Tests the route_concept_drift_alerts function that routes alerts
generated by the feedback loop's concept drift detection.

Tests cover:
- Alert creation with correct severity
- Alert routing to notification channels
- Handling of empty/missing alerts
- Rate limiting prevents duplicate alerts
- Alert payload contains recommended actions

Reference: .claude/plans/feedback-loop-concept-drift-audit.md (Phase 4)

Author: E2I Causal Analytics Team
Version: 1.0.0
"""

from unittest.mock import AsyncMock, MagicMock, patch

import pytest

from src.services.alert_routing import (
    AlertRoutingConfig,
    route_concept_drift_alerts,
)

# =============================================================================
# FIXTURES
# =============================================================================


@pytest.fixture
def mock_drift_results():
    """Mock drift results from v_drift_alerts view."""
    return [
        {
            "prediction_type": "trigger",
            "accuracy_status": "ALERT",
            "calibration_status": "OK",
            "accuracy_drop": 0.08,
            "calibration_error": 0.03,
            "baseline_accuracy": 0.82,
            "current_accuracy": 0.74,
            "predictions_count": 500,
        },
        {
            "prediction_type": "hcp_churn",
            "accuracy_status": "ALERT",
            "calibration_status": "WARNING",
            "accuracy_drop": 0.12,
            "calibration_error": 0.08,
            "baseline_accuracy": 0.78,
            "current_accuracy": 0.66,
            "predictions_count": 250,
        },
    ]


@pytest.fixture
def mock_alerts_high_severity():
    """Mock high-severity alerts from task."""
    return [
        {
            "type": "accuracy_degradation",
            "prediction_type": "trigger",
            "severity": "high",
            "metric": "accuracy_drop",
            "value": 0.08,
            "threshold": 0.05,
            "message": ("Accuracy dropped by 8.0% for trigger predictions (threshold: 5.0%)"),
        },
    ]


@pytest.fixture
def mock_alerts_critical_severity():
    """Mock critical-severity alerts from task."""
    return [
        {
            "type": "accuracy_degradation",
            "prediction_type": "hcp_churn",
            "severity": "critical",
            "metric": "accuracy_drop",
            "value": 0.12,
            "threshold": 0.05,
            "message": ("Accuracy dropped by 12.0% for hcp_churn predictions (threshold: 5.0%)"),
        },
    ]


@pytest.fixture
def mock_alerts_low_severity():
    """Mock low-severity alerts that should be skipped."""
    return [
        {
            "type": "accuracy_degradation",
            "prediction_type": "trigger",
            "severity": "low",
            "metric": "accuracy_drop",
            "value": 0.02,
            "threshold": 0.05,
            "message": "Minor accuracy change detected",
        },
    ]


@pytest.fixture
def mock_calibration_alerts():
    """Mock calibration drift alerts."""
    return [
        {
            "type": "calibration_drift",
            "prediction_type": "trigger",
            "severity": "medium",
            "metric": "calibration_error",
            "value": 0.12,
            "threshold": 0.10,
            "message": ("Calibration error of 12.0% for trigger predictions (threshold: 10.0%)"),
        },
    ]


@pytest.fixture
def default_config():
    """Create default alert routing configuration."""
    return AlertRoutingConfig(
        email_enabled=True,
        smtp_host="smtp.example.com",
        smtp_port=587,
        smtp_username="user",
        smtp_password="pass",
        email_from="alerts@example.com",
        email_recipients=["ml-team@example.com"],
        slack_enabled=True,
        slack_webhook_url="https://hooks.slack.com/test",
        slack_channel="#ml-alerts",
        webhook_enabled=False,
        min_interval_seconds=60,
        max_alerts_per_hour=100,
    )


# =============================================================================
# BASIC FUNCTIONALITY TESTS
# =============================================================================


class TestRouteConceptDriftAlertsBasic:
    """Tests for basic functionality of route_concept_drift_alerts."""

    @pytest.mark.asyncio
    async def test_returns_empty_list_when_no_alerts(self, mock_drift_results):
        """Test that empty alert list returns empty results."""
        result = await route_concept_drift_alerts(
            drift_results=mock_drift_results,
            alerts=[],
            baseline_days=90,
            current_days=30,
        )
        assert result == []

    @pytest.mark.asyncio
    async def test_returns_empty_list_when_alerts_none(self, mock_drift_results):
        """Test graceful handling of None alerts."""
        # Note: The function checks `if not alerts:` which handles None
        result = await route_concept_drift_alerts(
            drift_results=mock_drift_results,
            alerts=None,
            baseline_days=90,
            current_days=30,
        )
        assert result == []

    @pytest.mark.asyncio
    async def test_skips_low_severity_alerts(self, mock_drift_results, mock_alerts_low_severity):
        """Test that low-severity alerts are skipped."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[])
            mock_get_router.return_value = mock_router

            result = await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_low_severity,
                baseline_days=90,
                current_days=30,
            )

            # Should return empty since all alerts were low severity
            assert result == []
            # route_batch should not be called for low-severity alerts
            mock_router.route_batch.assert_not_called()


# =============================================================================
# SEVERITY TESTS
# =============================================================================


class TestAlertSeverity:
    """Tests for alert severity handling."""

    @pytest.mark.asyncio
    async def test_high_severity_alert_routed(self, mock_drift_results, mock_alerts_high_severity):
        """Test that high-severity alerts are routed correctly."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
                baseline_days=90,
                current_days=30,
            )

            mock_router.route_batch.assert_called_once()
            call_args = mock_router.route_batch.call_args[0][0]
            assert len(call_args) == 1
            assert call_args[0].severity == "high"
            assert "trigger" in call_args[0].title

    @pytest.mark.asyncio
    async def test_critical_severity_alert_routed(
        self, mock_drift_results, mock_alerts_critical_severity
    ):
        """Test that critical-severity alerts are routed correctly."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_critical_severity,
                baseline_days=90,
                current_days=30,
            )

            mock_router.route_batch.assert_called_once()
            call_args = mock_router.route_batch.call_args[0][0]
            assert len(call_args) == 1
            assert call_args[0].severity == "critical"
            assert "hcp_churn" in call_args[0].title

    @pytest.mark.asyncio
    async def test_medium_severity_calibration_alert(
        self, mock_drift_results, mock_calibration_alerts
    ):
        """Test that medium-severity calibration alerts are routed."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_calibration_alerts,
                baseline_days=90,
                current_days=30,
            )

            mock_router.route_batch.assert_called_once()
            call_args = mock_router.route_batch.call_args[0][0]
            assert len(call_args) == 1
            assert call_args[0].severity == "medium"


# =============================================================================
# ALERT PAYLOAD TESTS
# =============================================================================


class TestAlertPayloadContent:
    """Tests for alert payload content."""

    @pytest.mark.asyncio
    async def test_alert_payload_has_correct_type(
        self, mock_drift_results, mock_alerts_high_severity
    ):
        """Test that alert payload has correct alert_type."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            assert alert.alert_type == "concept_drift"

    @pytest.mark.asyncio
    async def test_alert_payload_has_recommended_actions(
        self, mock_drift_results, mock_alerts_high_severity
    ):
        """Test that alert payload includes recommended actions."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            assert len(alert.recommended_actions) > 0
            # For accuracy_degradation, should include retraining suggestion
            assert any("retrain" in action.lower() for action in alert.recommended_actions)

    @pytest.mark.asyncio
    async def test_calibration_alert_has_calibration_actions(
        self, mock_drift_results, mock_calibration_alerts
    ):
        """Test that calibration alerts have appropriate recommended actions."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_calibration_alerts,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            # For calibration_drift, should mention class distribution
            assert any(
                "class" in action.lower() or "calibration" in action.lower()
                for action in alert.recommended_actions
            )

    @pytest.mark.asyncio
    async def test_alert_payload_has_metadata(self, mock_drift_results, mock_alerts_high_severity):
        """Test that alert payload includes full metadata."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
                baseline_days=90,
                current_days=30,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            metadata = alert.metadata

            assert metadata["prediction_type"] == "trigger"
            assert metadata["alert_type"] == "accuracy_degradation"
            assert metadata["accuracy_drop"] == 0.08
            assert metadata["baseline_days"] == 90
            assert metadata["current_days"] == 30
            assert metadata["source"] == "feedback_loop"

    @pytest.mark.asyncio
    async def test_alert_description_includes_statistics(
        self, mock_drift_results, mock_alerts_high_severity
    ):
        """Test that alert description includes accuracy statistics."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            description = alert.description

            # Should include key metrics in description
            assert "74.0%" in description or "74%" in description  # current accuracy
            assert "8.0%" in description or "8%" in description  # accuracy drop


# =============================================================================
# MULTIPLE ALERTS TESTS
# =============================================================================


class TestMultipleAlerts:
    """Tests for handling multiple alerts."""

    @pytest.mark.asyncio
    async def test_multiple_alerts_batched(self, mock_drift_results):
        """Test that multiple alerts are batched together."""
        alerts = [
            {
                "type": "accuracy_degradation",
                "prediction_type": "trigger",
                "severity": "high",
                "metric": "accuracy_drop",
                "value": 0.08,
                "threshold": 0.05,
                "message": "Accuracy dropped for trigger",
            },
            {
                "type": "accuracy_degradation",
                "prediction_type": "hcp_churn",
                "severity": "critical",
                "metric": "accuracy_drop",
                "value": 0.12,
                "threshold": 0.05,
                "message": "Accuracy dropped for hcp_churn",
            },
        ]

        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(
                return_value=[
                    {"status": "sent"},
                    {"status": "sent"},
                ]
            )
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=alerts,
            )

            mock_router.route_batch.assert_called_once()
            call_args = mock_router.route_batch.call_args[0][0]
            assert len(call_args) == 2

    @pytest.mark.asyncio
    async def test_mixed_severity_alerts_filters_low(self, mock_drift_results):
        """Test that mixed severity alerts filter out low severity."""
        alerts = [
            {
                "type": "accuracy_degradation",
                "prediction_type": "trigger",
                "severity": "high",
                "metric": "accuracy_drop",
                "value": 0.08,
                "threshold": 0.05,
                "message": "High severity alert",
            },
            {
                "type": "accuracy_degradation",
                "prediction_type": "other",
                "severity": "low",
                "metric": "accuracy_drop",
                "value": 0.02,
                "threshold": 0.05,
                "message": "Low severity alert - should be skipped",
            },
        ]

        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=alerts,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            # Only 1 alert should be routed (high severity)
            assert len(call_args) == 1
            assert call_args[0].severity == "high"


# =============================================================================
# EDGE CASES
# =============================================================================


class TestEdgeCases:
    """Tests for edge cases and error handling."""

    @pytest.mark.asyncio
    async def test_missing_drift_result_for_prediction_type(self):
        """Test handling when drift result not found for prediction type."""
        drift_results = [
            {
                "prediction_type": "other_type",
                "accuracy_drop": 0.05,
            }
        ]
        alerts = [
            {
                "type": "accuracy_degradation",
                "prediction_type": "trigger",  # Not in drift_results
                "severity": "high",
                "metric": "accuracy_drop",
                "value": 0.08,
                "threshold": 0.05,
                "message": "Alert for missing type",
            },
        ]

        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            # Should not raise, but use default values
            await route_concept_drift_alerts(
                drift_results=drift_results,
                alerts=alerts,
            )

            # Alert should still be created with default values
            call_args = mock_router.route_batch.call_args[0][0]
            assert len(call_args) == 1
            # Metadata should have default values
            assert call_args[0].metadata["accuracy_drop"] == 0.0

    @pytest.mark.asyncio
    async def test_handles_empty_drift_results(self, mock_alerts_high_severity):
        """Test handling when drift_results is empty."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            # Should not raise
            await route_concept_drift_alerts(
                drift_results=[],
                alerts=mock_alerts_high_severity,
            )

            # Alert should still be created
            call_args = mock_router.route_batch.call_args[0][0]
            assert len(call_args) == 1

    @pytest.mark.asyncio
    async def test_default_baseline_and_current_days(
        self, mock_drift_results, mock_alerts_high_severity
    ):
        """Test that default values are used for baseline and current days."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
                # Using defaults
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            assert alert.metadata["baseline_days"] == 90
            assert alert.metadata["current_days"] == 30

    @pytest.mark.asyncio
    async def test_alert_id_contains_prediction_type(
        self, mock_drift_results, mock_alerts_high_severity
    ):
        """Test that alert_id contains the prediction type."""
        with patch("src.services.alert_routing.get_alert_router") as mock_get_router:
            mock_router = MagicMock()
            mock_router.route_batch = AsyncMock(return_value=[{"status": "sent"}])
            mock_get_router.return_value = mock_router

            await route_concept_drift_alerts(
                drift_results=mock_drift_results,
                alerts=mock_alerts_high_severity,
            )

            call_args = mock_router.route_batch.call_args[0][0]
            alert = call_args[0]
            assert "trigger" in alert.alert_id
            assert "concept-drift" in alert.alert_id
