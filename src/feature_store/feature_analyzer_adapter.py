"""Feature Analyzer Adapter

Bridges the feature_analyzer agent output with the FeatureStoreClient.
Registers generated/selected features in the feature store for:
- Version tracking
- Reuse across experiments
- Online serving

Also integrates with Feast for:
- Point-in-time correct feature retrieval (training data)
- Feature discovery from registry
- Feature freshness monitoring
"""

import hashlib
import logging
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

import pandas as pd

from .client import FeatureStoreClient
from .feast_client import FeastClient
from .models import FeatureGroup, FeatureValueType

logger = logging.getLogger(__name__)


# Feature type mapping
PYTHON_TO_FEATURE_TYPE = {
    "int64": FeatureValueType.INT64,
    "int32": FeatureValueType.INT64,
    "float64": FeatureValueType.FLOAT64,
    "float32": FeatureValueType.FLOAT64,
    "object": FeatureValueType.STRING,
    "bool": FeatureValueType.BOOL,
    "datetime64[ns]": FeatureValueType.TIMESTAMP,
}


class FeatureAnalyzerAdapter:
    """
    Adapter to register features from feature_analyzer to feature store.

    This class provides:
    - Automatic feature registration from analyzer output
    - Feature versioning based on generation config
    - Batch writing of feature values for training data
    - Feature group management for experiments
    - Feast integration for point-in-time correct features
    - Feature discovery from Feast registry
    - Feature freshness monitoring

    Example:
        ```python
        from src.feature_store import FeatureStoreClient
        from src.feature_store.feature_analyzer_adapter import FeatureAnalyzerAdapter

        fs_client = FeatureStoreClient(...)
        adapter = FeatureAnalyzerAdapter(fs_client)

        # Register features from feature_analyzer state
        await adapter.register_features_from_state(
            state=analyzer_state,
            experiment_id="exp_001",
            entity_key="hcp_id",
        )

        # Get point-in-time correct training data from Feast
        training_df = await adapter.get_training_features(
            entity_df=entity_df,
            feature_refs=["hcp_conversion_features:*"],
        )
        ```
    """

    def __init__(
        self,
        feature_store_client: FeatureStoreClient,
        feast_client: Optional[FeastClient] = None,
        auto_create_groups: bool = True,
        enable_feast: bool = True,
    ):
        """
        Initialize adapter.

        Args:
            feature_store_client: Initialized FeatureStoreClient instance
            feast_client: Optional Feast client (created if not provided)
            auto_create_groups: Automatically create feature groups if not exist
            enable_feast: Enable Feast integration
        """
        self.fs_client = feature_store_client
        self.auto_create_groups = auto_create_groups
        self.enable_feast = enable_feast
        self._feast_client = feast_client
        self._feast_initialized = False

    async def register_features_from_state(
        self,
        state: Dict[str, Any],
        experiment_id: str,
        entity_key: str,
        owner: Optional[str] = None,
        tags: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        Register generated and selected features from feature_analyzer state.

        Args:
            state: Feature analyzer state containing:
                - generated_features: List of generated feature metadata
                - selected_features: List of selected feature names
                - feature_importance: Dict of feature importance scores
                - X_train_selected: DataFrame with selected features
            experiment_id: Experiment identifier for grouping
            entity_key: Primary entity key for features (e.g., "hcp_id")
            owner: Feature owner/team
            tags: Tags for organization

        Returns:
            Dict with registration results
        """
        results: Dict[str, Any] = {
            "feature_group_created": False,
            "features_registered": 0,
            "features_skipped": 0,
            "errors": [],
        }

        try:
            # Create feature group for this experiment
            group_name = f"feature_analyzer_{experiment_id}"
            feature_group = self._ensure_feature_group(
                name=group_name,
                description=f"Features generated by feature_analyzer for experiment {experiment_id}",
                owner=owner,
                tags=tags or ["feature_analyzer", "generated"],
            )

            if feature_group:
                results["feature_group_created"] = True

            # Get generated feature metadata
            generated_features = state.get("generated_features", [])
            selected_features = state.get("selected_features", [])
            feature_importance = state.get("feature_importance", {})

            # Get DataFrame for type inference
            X_selected = state.get("X_train_selected")
            if X_selected is None:
                X_selected = state.get("X_train")

            # Register each selected feature
            for feature_meta in generated_features:
                feature_name = feature_meta.get("name")
                if not feature_name:
                    continue

                # Skip if not in selected features
                if selected_features and feature_name not in selected_features:
                    results["features_skipped"] += 1
                    continue

                try:
                    # Determine value type
                    if X_selected is not None and feature_name in X_selected.columns:
                        dtype = str(X_selected[feature_name].dtype)
                        value_type = PYTHON_TO_FEATURE_TYPE.get(dtype, FeatureValueType.STRING)
                    else:
                        value_type = FeatureValueType.FLOAT64

                    # Build feature description
                    description_parts = []
                    if feature_meta.get("type"):
                        description_parts.append(f"Type: {feature_meta['type']}")
                    if feature_meta.get("transformation"):
                        description_parts.append(
                            f"Transformation: {feature_meta['transformation']}"
                        )
                    if feature_meta.get("source"):
                        description_parts.append(f"Source: {feature_meta['source']}")
                    if feature_meta.get("sources"):
                        description_parts.append(f"Sources: {', '.join(feature_meta['sources'])}")

                    # Add importance score
                    importance = feature_importance.get(feature_name)
                    if importance:
                        description_parts.append(f"Importance: {importance:.4f}")

                    # Create feature
                    self.fs_client.create_feature(
                        feature_group_name=group_name,
                        name=feature_name,
                        value_type=value_type.value,
                        entity_keys=[entity_key],
                        description=" | ".join(description_parts) if description_parts else None,
                        owner=owner,
                        tags=[
                            feature_meta.get("type", "generated"),
                            feature_meta.get("transformation", "unknown"),
                        ],
                    )

                    results["features_registered"] += 1

                except Exception as e:
                    results["errors"].append(
                        {
                            "feature": feature_name,
                            "error": str(e),
                        }
                    )
                    logger.warning(f"Failed to register feature {feature_name}: {e}")

            logger.info(
                f"Registered {results['features_registered']} features "
                f"(skipped {results['features_skipped']}) for experiment {experiment_id}"
            )

            return results

        except Exception as e:
            logger.exception("Feature registration failed")
            results["errors"].append({"error": str(e)})
            return results

    async def write_training_features(
        self,
        state: Dict[str, Any],
        experiment_id: str,
        entity_key: str,
        entity_id_column: str,
        timestamp_column: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Write feature values from training data to feature store.

        This enables online serving of the same features used in training.

        Args:
            state: Feature analyzer state
            experiment_id: Experiment identifier
            entity_key: Entity key name (e.g., "hcp_id")
            entity_id_column: Column containing entity IDs
            timestamp_column: Column containing event timestamps (optional)

        Returns:
            Dict with write results
        """
        results: Dict[str, Any] = {
            "values_written": 0,
            "errors": [],
        }

        try:
            X_selected = state.get("X_train_selected")
            if X_selected is None:
                results["errors"].append("No training data in state")
                return results

            selected_features = state.get("selected_features", [])
            if not selected_features:
                selected_features = [c for c in X_selected.columns if c != entity_id_column]

            group_name = f"feature_analyzer_{experiment_id}"
            now = datetime.now(timezone.utc)

            # Prepare batch writes
            batch_values = []
            for _, row in X_selected.iterrows():
                entity_id = row.get(entity_id_column)
                if not entity_id:
                    continue

                timestamp = row.get(timestamp_column, now) if timestamp_column else now

                for feature_name in selected_features:
                    if feature_name in [entity_id_column, timestamp_column]:
                        continue

                    value = row.get(feature_name)
                    if pd.isna(value):
                        continue

                    batch_values.append(
                        {
                            "feature_name": feature_name,
                            "entity_values": {entity_key: str(entity_id)},
                            "value": value
                            if not isinstance(value, (pd.Timestamp, datetime))
                            else value.isoformat(),
                            "event_timestamp": timestamp,
                            "feature_group": group_name,
                        }
                    )

            # Write in batches
            if batch_values:
                written = self.fs_client.write_batch_features(
                    feature_values=batch_values,
                    invalidate_cache=True,
                )
                results["values_written"] = written

            logger.info(
                f"Wrote {results['values_written']} feature values for experiment {experiment_id}"
            )

        except Exception as e:
            logger.exception("Feature value writing failed")
            results["errors"].append(str(e))

        return results

    def _ensure_feature_group(
        self,
        name: str,
        description: Optional[str] = None,
        owner: Optional[str] = None,
        tags: Optional[List[str]] = None,
    ) -> Optional[FeatureGroup]:
        """
        Ensure feature group exists, create if not.

        Args:
            name: Feature group name
            description: Group description
            owner: Owner name
            tags: Tags

        Returns:
            FeatureGroup instance or None if creation disabled
        """
        # Check if exists
        existing = self.fs_client.get_feature_group(name)
        if existing:
            return existing

        # Create if auto-creation enabled
        if self.auto_create_groups:
            try:
                return self.fs_client.create_feature_group(
                    name=name,
                    description=description,
                    owner=owner,
                    tags=tags,
                )
            except Exception as e:
                logger.warning(f"Failed to create feature group {name}: {e}")
                return None

        return None

    def get_feature_version_hash(
        self,
        feature_config: Dict[str, Any],
        selected_features: List[str],
    ) -> str:
        """
        Generate a version hash for feature configuration.

        This enables tracking which feature configuration produced which features.

        Args:
            feature_config: Feature generation configuration
            selected_features: List of selected feature names

        Returns:
            Version hash string
        """
        # Create deterministic representation
        config_str = str(sorted(feature_config.items()))
        features_str = ",".join(sorted(selected_features))
        combined = f"{config_str}:{features_str}"

        return hashlib.md5(combined.encode()).hexdigest()[:8]

    # =========================================================================
    # Feast Integration Methods
    # =========================================================================

    async def _ensure_feast_initialized(self) -> bool:
        """
        Ensure Feast client is initialized (lazy initialization).

        Returns:
            True if Feast is available and initialized
        """
        if not self.enable_feast:
            return False

        if self._feast_initialized:
            return True

        try:
            if self._feast_client is None:
                self._feast_client = FeastClient()

            await self._feast_client.initialize()
            self._feast_initialized = True
            logger.info("Feast client initialized successfully")
            return True

        except Exception as e:
            logger.warning(f"Failed to initialize Feast client: {e}")
            self._feast_initialized = False
            return False

    async def get_training_features(
        self,
        entity_df: pd.DataFrame,
        feature_refs: List[str],
        full_feature_names: bool = True,
    ) -> pd.DataFrame:
        """
        Get point-in-time correct training features from Feast.

        This method retrieves historical features with proper point-in-time joins
        to prevent data leakage during model training.

        Args:
            entity_df: DataFrame with entity columns and event_timestamp
                Must contain:
                - Entity columns (e.g., hcp_id, brand_id)
                - event_timestamp column for point-in-time joins
            feature_refs: List of feature references in format:
                - "feature_view:feature_name" (specific feature)
                - "feature_view:*" (all features from view)
            full_feature_names: Use full feature names in output

        Returns:
            DataFrame with entity columns and requested features

        Raises:
            ValueError: If entity_df is empty or missing event_timestamp

        Example:
            ```python
            entity_df = pd.DataFrame({
                "hcp_id": ["hcp_001", "hcp_002"],
                "brand_id": ["remibrutinib", "remibrutinib"],
                "event_timestamp": [datetime(2024, 1, 1), datetime(2024, 1, 15)],
            })

            training_df = await adapter.get_training_features(
                entity_df=entity_df,
                feature_refs=[
                    "hcp_conversion_features:engagement_score",
                    "hcp_conversion_features:trx_count",
                ],
            )
            ```
        """
        # Validate inputs
        if entity_df is None or len(entity_df) == 0:
            raise ValueError("entity_df cannot be empty")

        if "event_timestamp" not in entity_df.columns:
            raise ValueError(
                "entity_df must contain 'event_timestamp' column for point-in-time joins"
            )

        if not feature_refs:
            raise ValueError("feature_refs cannot be empty")

        # Try Feast first
        feast_available = await self._ensure_feast_initialized()

        if feast_available and self._feast_client:
            try:
                result = await self._feast_client.get_historical_features(
                    entity_df=entity_df,
                    feature_refs=feature_refs,
                    full_feature_names=full_feature_names,
                )
                logger.info(
                    f"Retrieved {len(result)} rows with {len(result.columns)} features from Feast"
                )
                return result

            except Exception as e:
                logger.warning(f"Feast historical feature retrieval failed: {e}")
                # Fall through to custom store

        # Fallback to custom store (without point-in-time joins)
        logger.warning("Falling back to custom store - point-in-time joins not available")
        return await self._get_features_from_custom_store(
            entity_df=entity_df,
            feature_refs=feature_refs,
        )

    async def _get_features_from_custom_store(
        self,
        entity_df: pd.DataFrame,
        feature_refs: List[str],
    ) -> pd.DataFrame:
        """
        Fallback to get features from custom store.

        Note: This does NOT provide point-in-time correct joins.

        Args:
            entity_df: Entity DataFrame
            feature_refs: Feature references

        Returns:
            DataFrame with features (latest values only)
        """
        result_df = entity_df.copy()

        for feature_ref in feature_refs:
            parts = feature_ref.split(":")
            if len(parts) != 2:
                continue

            feature_view, feature_name = parts

            # Skip wildcard refs in fallback mode
            if feature_name == "*":
                logger.warning(
                    f"Wildcard feature refs not supported in fallback mode: {feature_ref}"
                )
                continue

            # Get from custom store
            try:
                # Build entity keys from first row to get feature group
                # This is a simplified fallback - not point-in-time correct
                entity_features = self.fs_client.get_entity_features(
                    feature_names=[feature_name],
                    entity_values={},  # Empty - get latest
                )
                if entity_features and feature_name in entity_features.features:
                    result_df[f"{feature_view}__{feature_name}"] = entity_features.features[feature_name]

            except Exception as e:
                logger.warning(f"Failed to get feature {feature_ref} from custom store: {e}")

        return result_df

    async def discover_features(
        self,
        use_case: Optional[str] = None,
        entity_names: Optional[List[str]] = None,
    ) -> List[Dict[str, Any]]:
        """
        Discover available features from Feast registry.

        This helps the feature_analyzer agent understand what features
        are already available before generating new ones.

        Args:
            use_case: Filter by use_case tag (e.g., "hcp_conversion", "churn_prediction")
            entity_names: Filter by entity names (e.g., ["hcp", "brand"])

        Returns:
            List of feature metadata dicts with keys:
                - feature_view: Name of the feature view
                - feature_name: Name of the feature
                - dtype: Data type
                - entities: List of entity names
                - tags: Dict of tags
                - description: Feature description

        Example:
            ```python
            # Get all HCP conversion features
            features = await adapter.discover_features(use_case="hcp_conversion")

            # Get all features for HCP entity
            features = await adapter.discover_features(entity_names=["hcp"])
            ```
        """
        discovered = []

        feast_available = await self._ensure_feast_initialized()

        if feast_available and self._feast_client:
            try:
                feature_views = await self._feast_client.list_feature_views()

                for fv in feature_views:
                    # Apply use_case filter
                    if use_case and fv.get("tags", {}).get("use_case") != use_case:
                        continue

                    # Apply entity filter
                    if entity_names:
                        fv_entities = set(fv.get("entities", []))
                        if not fv_entities.intersection(set(entity_names)):
                            continue

                    # Extract features from view
                    for field in fv.get("schema", []):
                        discovered.append(
                            {
                                "feature_view": fv.get("name"),
                                "feature_name": field.get("name"),
                                "dtype": field.get("dtype"),
                                "entities": fv.get("entities", []),
                                "tags": fv.get("tags", {}),
                                "description": field.get("description", ""),
                                "online": fv.get("online", False),
                                "ttl_days": fv.get("ttl_days"),
                            }
                        )

                logger.info(f"Discovered {len(discovered)} features from Feast registry")

            except Exception as e:
                logger.warning(f"Feature discovery from Feast failed: {e}")

        # Also check custom store for registered features
        try:
            groups = self.fs_client.list_feature_groups()
            for group in groups:
                features = self.fs_client.list_features(feature_group_name=group.name)
                for feature in features:
                    discovered.append(
                        {
                            "feature_view": group.name,
                            "feature_name": feature.name,
                            "dtype": feature.value_type,
                            "entities": feature.entity_keys or [],
                            "tags": {"source": "custom_store"},
                            "description": feature.description or "",
                            "online": True,
                            "ttl_days": None,
                        }
                    )

        except Exception as e:
            logger.warning(f"Feature discovery from custom store failed: {e}")

        return discovered

    async def check_feature_freshness(
        self,
        feature_refs: List[str],
        max_staleness_hours: float = 24.0,
    ) -> Dict[str, Any]:
        """
        Check freshness of features for data quality validation.

        This is used by the QC Gate to ensure features are up-to-date
        before using them for training or inference.

        Args:
            feature_refs: Feature references to check
            max_staleness_hours: Maximum allowed staleness in hours

        Returns:
            Dict with:
                - fresh: True if all features are fresh
                - stale_features: List of stale feature refs
                - feature_ages: Dict of feature ref -> age in hours
                - recommendations: List of remediation suggestions

        Example:
            ```python
            freshness = await adapter.check_feature_freshness(
                feature_refs=["hcp_conversion_features:engagement_score"],
                max_staleness_hours=24.0,
            )

            if not freshness["fresh"]:
                print(f"Stale features: {freshness['stale_features']}")
            ```
        """
        result: Dict[str, Any] = {
            "fresh": True,
            "stale_features": [],
            "feature_ages": {},
            "recommendations": [],
            "checked_at": datetime.now(timezone.utc).isoformat(),
        }

        feast_available = await self._ensure_feast_initialized()

        if not feast_available or not self._feast_client:
            result["recommendations"].append(
                "Feast not available - feature freshness cannot be verified"
            )
            return result

        now = datetime.now(timezone.utc)

        for feature_ref in feature_refs:
            parts = feature_ref.split(":")
            if len(parts) != 2:
                continue

            feature_view, feature_name = parts

            try:
                stats = await self._feast_client.get_feature_statistics(
                    feature_view=feature_view,
                    feature_name=feature_name if feature_name != "*" else "",  # type: ignore[arg-type]
                )

                if stats and stats.last_updated:
                    age_hours = (now - stats.last_updated).total_seconds() / 3600
                    result["feature_ages"][feature_ref] = age_hours

                    if age_hours > max_staleness_hours:
                        result["fresh"] = False
                        result["stale_features"].append(feature_ref)
                        result["recommendations"].append(
                            f"Run materialization for {feature_view} "
                            f"(last updated {age_hours:.1f} hours ago)"
                        )
                else:
                    result["feature_ages"][feature_ref] = None
                    result["recommendations"].append(f"No statistics available for {feature_ref}")

            except Exception as e:
                logger.warning(f"Failed to check freshness for {feature_ref}: {e}")
                result["feature_ages"][feature_ref] = None

        if result["fresh"]:
            logger.info(f"All {len(feature_refs)} features are fresh")
        else:
            logger.warning(
                f"{len(result['stale_features'])} of {len(feature_refs)} features are stale"
            )

        return result

    async def sync_features_to_feast(
        self,
        experiment_id: str,
        entity_key: str,
        materialize: bool = True,
    ) -> Dict[str, Any]:
        """
        Sync features registered in custom store to Feast.

        This bridges the gap during migration, ensuring features registered
        by feature_analyzer are available in Feast for point-in-time joins.

        Args:
            experiment_id: Experiment identifier
            entity_key: Entity key name
            materialize: Whether to materialize after sync

        Returns:
            Dict with sync results
        """
        result: Dict[str, Any] = {
            "synced": False,
            "features_synced": 0,
            "materialized": False,
            "errors": [],
        }

        feast_available = await self._ensure_feast_initialized()
        if not feast_available:
            result["errors"].append("Feast not available")
            return result

        group_name = f"feature_analyzer_{experiment_id}"

        try:
            # Get features from custom store
            features = self.fs_client.list_features(feature_group_name=group_name)

            if not features:
                result["errors"].append(f"No features found in group {group_name}")
                return result

            # Note: Actual sync would require Feast feature definitions
            # This is a placeholder for the migration pattern
            logger.info(f"Would sync {len(features)} features from {group_name} to Feast")
            result["features_synced"] = len(features)
            result["synced"] = True

            # Materialize if requested
            if materialize and self._feast_client:
                mat_result = await self._feast_client.materialize_incremental(
                    end_date=datetime.now(timezone.utc)
                )
                result["materialized"] = mat_result.get("status") == "completed"

        except Exception as e:
            logger.exception(f"Feature sync to Feast failed: {e}")
            result["errors"].append(str(e))

        return result


def get_feature_analyzer_adapter(
    feature_store_client: FeatureStoreClient,
    feast_client: Optional[FeastClient] = None,
    enable_feast: bool = True,
) -> FeatureAnalyzerAdapter:
    """
    Factory function to create FeatureAnalyzerAdapter.

    Args:
        feature_store_client: Initialized FeatureStoreClient
        feast_client: Optional Feast client (created lazily if not provided)
        enable_feast: Enable Feast integration (default True)

    Returns:
        FeatureAnalyzerAdapter instance
    """
    return FeatureAnalyzerAdapter(
        feature_store_client=feature_store_client,
        feast_client=feast_client,
        enable_feast=enable_feast,
    )
