# Agent Handoff Standard Format
# Version: 1.0
# Last Updated: 2025-12-18
# Purpose: Define standard YAML handoff format for inter-agent communication

# ==============================================================================
# HANDOFF SCHEMA DEFINITION
# ==============================================================================

handoff_schema:
  version: "1.0"
  description: "Standard format for passing context between E2I agents"

  # Required fields (ALL handoffs must include these)
  required_fields:
    - agent                 # Agent name producing this handoff
    - analysis_type         # Type of analysis performed
    - status                # "completed" | "partial" | "failed"
    - confidence            # Confidence score 0.0-1.0
    - key_findings          # List of key findings (max 5)

  # Optional fields (include when applicable)
  optional_fields:
    - outputs               # Primary outputs (agent-specific structure)
    - assumptions           # Assumptions made
    - limitations           # Known limitations
    - warnings              # Warnings for downstream agents
    - recommendations       # Recommendations for next steps
    - requires_further_analysis  # Boolean flag
    - suggested_next_agent  # Agent name to route to next
    - context_for_next_agent    # Additional context
    - data_sources          # Data sources used
    - execution_time_ms     # Execution duration

  # Validation rules
  validation:
    agent:
      type: string
      allowed_values:
        - scope_definer
        - data_preparer
        - model_selector
        - model_trainer
        - feature_analyzer
        - model_deployer
        - observability_connector
        - orchestrator
        - causal_impact
        - gap_analyzer
        - heterogeneous_optimizer
        - experiment_designer
        - drift_monitor
        - health_score
        - prediction_synthesizer
        - resource_optimizer
        - explainer
        - feedback_learner

    status:
      type: string
      allowed_values: ["completed", "partial", "failed"]

    confidence:
      type: float
      min: 0.0
      max: 1.0

    key_findings:
      type: array
      item_type: string
      max_items: 5
      min_items: 1

# ==============================================================================
# TIER 0: ML FOUNDATION HANDOFFS
# ==============================================================================

# ============
# scope_definer
# ============
scope_definer_handoff:
  agent: scope_definer
  analysis_type: problem_definition
  status: completed
  confidence: 0.95

  key_findings:
    - "Problem type: binary_classification"
    - "Target variable: patient_conversion"
    - "Required features: 15 identified"
    - "Success criteria: F1 > 0.85, Precision > 0.80"
    - "Scope validated against business requirements"

  outputs:
    scope_spec:
      experiment_id: "exp_abc123"
      problem_type: "binary_classification"
      prediction_target: "patient_conversion"
      required_features:
        - call_frequency
        - hcp_specialty
        - patient_volume
        - prior_conversion_rate
        - territory_potential
      excluded_features:
        - patient_name
        - hcp_address
      success_criteria:
        min_f1_score: 0.85
        min_precision: 0.80
        min_recall: 0.75
        max_training_time_hours: 4

  assumptions:
    - "Historical data is representative of future"
    - "Features are available at prediction time"
    - "Success criteria aligned with business needs"

  limitations:
    - "Cannot predict outcomes beyond 90 days"
    - "Requires minimum 10,000 training samples"

  requires_further_analysis: false
  suggested_next_agent: data_preparer

# ============
# data_preparer
# ============
data_preparer_handoff:
  agent: data_preparer
  analysis_type: data_quality_check
  status: completed
  confidence: 0.92

  key_findings:
    - "QC status: PASSED (score: 0.92)"
    - "Data leakage: NONE detected"
    - "Baseline metrics computed from training set"
    - "15/15 required features present"
    - "Training set: 42,000 samples (60%)"

  outputs:
    qc_report:
      report_id: "qc_exp_abc123_20251218"
      status: "passed"
      overall_score: 0.92
      completeness_score: 0.95
      validity_score: 0.94
      consistency_score: 0.91
      uniqueness_score: 0.88
      timeliness_score: 0.94
      blocking_issues: []

    baseline_metrics:
      experiment_id: "exp_abc123"
      split_type: "train"
      target_rate: 0.34  # 34% positive rate
      training_samples: 42000
      feature_stats:
        call_frequency:
          mean: 4.2
          std: 2.1
          percentiles:
            25: 2.0
            50: 4.0
            75: 6.0

    data_readiness:
      is_ready: true
      total_samples: 70000
      train_samples: 42000
      validation_samples: 14000
      test_samples: 10500
      holdout_samples: 3500
      qc_passed: true
      blockers: []

  warnings:
    - "Feature 'prior_conversion_rate' has 2% missing values (imputed)"

  requires_further_analysis: false
  suggested_next_agent: model_selector
  context_for_next_agent:
    qc_gate_passed: true
    baseline_metrics_available: true

# ============
# model_trainer
# ============
model_trainer_handoff:
  agent: model_trainer
  analysis_type: model_training
  status: completed
  confidence: 0.88

  key_findings:
    - "Training completed: XGBoost classifier"
    - "Validation F1: 0.87 (exceeds threshold)"
    - "Validation Precision: 0.85 (exceeds threshold)"
    - "100 Optuna trials completed"
    - "Model registered in MLflow"

  outputs:
    trained_model:
      model_id: "model_exp_abc123_v1"
      experiment_id: "exp_abc123"
      algorithm: "XGBoostClassifier"
      hyperparameters:
        n_estimators: 500
        max_depth: 8
        learning_rate: 0.05
        subsample: 0.8

    validation_metrics:
      f1_score: 0.87
      precision: 0.85
      recall: 0.89
      accuracy: 0.84
      auc_roc: 0.92
      confusion_matrix:
        tp: 4230
        fp: 740
        fn: 520
        tn: 8510

    mlflow_info:
      run_id: "mlflow_run_xyz789"
      model_uri: "runs:/mlflow_run_xyz789/model"
      registered_model_name: "e2i-kisqali-conversion"
      version: 1
      stage: "Staging"

  assumptions:
    - "Validation set is representative of production"
    - "Hyperparameters are near-optimal"

  limitations:
    - "Model may not generalize to new territories"
    - "Retraining recommended quarterly"

  requires_further_analysis: true
  suggested_next_agent: feature_analyzer
  context_for_next_agent:
    model_uri: "runs:/mlflow_run_xyz789/model"
    validation_passed: true

# ============
# feature_analyzer
# ============
feature_analyzer_handoff:
  agent: feature_analyzer
  analysis_type: feature_importance_shap
  status: completed
  confidence: 0.90

  key_findings:
    - "Top 3 features: call_frequency, prior_conversion_rate, territory_potential"
    - "5 feature interactions detected"
    - "call_frequency × territory_potential strongest interaction"
    - "SHAP values computed for 1,000 samples"
    - "Feature relationships stored in semantic memory"

  outputs:
    feature_importance:
      - feature: call_frequency
        importance: 0.28
        rank: 1
      - feature: prior_conversion_rate
        importance: 0.22
        rank: 2
      - feature: territory_potential
        importance: 0.18
        rank: 3

    interactions:
      - features: [call_frequency, territory_potential]
        interaction_strength: 0.15
        interpretation: "Call frequency more effective in high-potential territories"

      - features: [hcp_specialty, patient_volume]
        interaction_strength: 0.09
        interpretation: "Specialty effects vary by practice size"

    shap_analysis_id: "shap_exp_abc123_v1"

  assumptions:
    - "SHAP values capture true feature importance"
    - "Sample of 1,000 is representative"

  requires_further_analysis: false
  suggested_next_agent: model_deployer

# ==============================================================================
# TIER 1: ORCHESTRATION (no handoffs - orchestrator is terminal)
# ==============================================================================

# ==============================================================================
# TIER 2: CAUSAL INFERENCE HANDOFFS
# ==============================================================================

# ============
# causal_impact
# ============
causal_impact_handoff:
  agent: causal_impact
  analysis_type: causal_effect_estimation
  status: completed
  confidence: 0.85

  key_findings:
    - "Causal effect detected: +18% NRx"
    - "95% CI: [12%, 24%]"
    - "p-value: 0.003 (highly significant)"
    - "Refutation tests: PASSED"
    - "Primary driver: HCP engagement frequency"

  outputs:
    effect_estimate:
      treatment: "enhanced_targeting"
      outcome: "NRx"
      ate: 0.18  # 18% lift
      ate_ci_lower: 0.12
      ate_ci_upper: 0.24
      p_value: 0.003
      sample_size: 45000
      method: "double_machine_learning"

    causal_paths:
      - path: ["enhanced_targeting", "hcp_engagement", "NRx"]
        effect_size: 0.18
        confidence: 0.85

      - path: ["enhanced_targeting", "sample_utilization", "NRx"]
        effect_size: 0.05
        confidence: 0.72

    refutation_report:
      all_passed: true
      tests_run: ["random_common_cause", "placebo_treatment", "data_subset"]

  assumptions:
    - "Positivity: overlap assumption holds"
    - "Unconfoundedness: no unmeasured confounders"
    - "SUTVA: no interference between units"

  limitations:
    - "Effect estimate for 3-month time horizon only"
    - "Results may not generalize beyond Midwest region"

  warnings:
    - "Sensitivity to unobserved confounders: R²_Y~Z|X,W = 0.18"

  requires_further_analysis: true
  suggested_next_agent: gap_analyzer
  context_for_next_agent:
    causal_effect_confirmed: true
    effect_size: 0.18

# ============
# gap_analyzer
# ============
gap_analyzer_handoff:
  agent: gap_analyzer
  analysis_type: roi_opportunity_detection
  status: completed
  confidence: 0.82

  key_findings:
    - "3 high-ROI opportunities identified"
    - "Top opportunity: Midwest middle-decile HCPs (est. ROI: 4.2x)"
    - "Total incremental revenue potential: $2.8M"
    - "Implementation difficulty: Medium"
    - "Gaps exist in territories 14, 22, 35"

  outputs:
    opportunities:
      - opportunity_id: "opp_001"
        description: "Target middle-decile HCPs in Midwest"
        estimated_roi: 4.2
        estimated_incremental_revenue: 2800000
        implementation_difficulty: "medium"
        affected_territories: [14, 22, 35]

      - opportunity_id: "opp_002"
        description: "Increase sample allocation to high-responders"
        estimated_roi: 3.1
        estimated_incremental_revenue: 1200000
        implementation_difficulty: "low"

    gaps:
      - territory: 14
        gap_type: "underserved_segment"
        current_performance: 0.65
        benchmark_performance: 0.82
        potential_lift: 0.17

  assumptions:
    - "ROI calculations based on historical conversion rates"
    - "Benchmark derived from top 20% territories"

  limitations:
    - "ROI estimates have ±20% margin of error"

  requires_further_analysis: true
  suggested_next_agent: heterogeneous_optimizer

# ============
# heterogeneous_optimizer
# ============
heterogeneous_optimizer_handoff:
  agent: heterogeneous_optimizer
  analysis_type: cate_estimation
  status: completed
  confidence: 0.79

  key_findings:
    - "Treatment effects vary by segment (CATE detected)"
    - "High-volume HCPs: +25% effect"
    - "Low-volume HCPs: +8% effect"
    - "Academic centers: +32% effect"
    - "Community practices: +12% effect"

  outputs:
    cate_by_segment:
      hcp_volume:
        high: 0.25
        medium: 0.18
        low: 0.08

      practice_type:
        academic: 0.32
        community: 0.12

    recommendations:
      - segment: "academic_high_volume"
        recommendation: "Prioritize this segment for maximum ROI"
        expected_effect: 0.32

      - segment: "community_low_volume"
        recommendation: "Consider alternative engagement strategies"
        expected_effect: 0.08

  requires_further_analysis: false
  suggested_next_agent: explainer

# ==============================================================================
# TIER 3: DESIGN & MONITORING HANDOFFS
# ==============================================================================

# ============
# experiment_designer
# ============
experiment_designer_handoff:
  agent: experiment_designer
  analysis_type: experiment_design
  status: completed
  confidence: 0.88

  key_findings:
    - "Cluster RCT design recommended"
    - "Sample size: 90 territories (45 per arm)"
    - "Power: 80% to detect 10% effect"
    - "Duration: 12 weeks"
    - "Stratification: region + potential_decile"

  outputs:
    experiment_design:
      design_type: "cluster_rct"
      randomization_unit: "territory"
      treatment_description: "AI-driven targeting"
      control_description: "Standard targeting"
      sample_size:
        n_treatment: 45
        n_control: 45
      duration_weeks: 12
      stratification_variables:
        - region
        - potential_decile
      primary_outcome: "NRx"
      power_analysis:
        mde: 0.10
        power: 0.80
        alpha: 0.05

  assumptions:
    - "ICC = 0.15 (based on historical data)"
    - "No contamination between territories"

  limitations:
    - "Cannot detect effects smaller than 10%"
    - "12-week duration may miss long-term effects"

  requires_further_analysis: false
  suggested_next_agent: null

# ============
# drift_monitor
# ============
drift_monitor_handoff:
  agent: drift_monitor
  analysis_type: drift_detection
  status: completed
  confidence: 0.91

  key_findings:
    - "Data drift detected in 3 features"
    - "call_frequency: PSI = 0.28 (ALERT)"
    - "Model performance stable (no concept drift)"
    - "Recommendation: Retrain within 2 weeks"
    - "Affected regions: Midwest, Southeast"

  outputs:
    drift_report:
      data_drift_detected: true
      features_drifted:
        - feature: call_frequency
          psi: 0.28
          severity: "high"
          threshold: 0.25

        - feature: territory_potential
          psi: 0.18
          severity: "moderate"
          threshold: 0.25

      concept_drift_detected: false

      model_performance:
        current_f1: 0.85
        baseline_f1: 0.87
        degradation: 0.02
        alert_threshold: 0.05

    recommendations:
      - action: "retrain_model"
        urgency: "high"
        timeline: "within_2_weeks"

      - action: "investigate_cause"
        feature: "call_frequency"
        regions: ["Midwest", "Southeast"]

  warnings:
    - "If not addressed, model performance may degrade further"

  requires_further_analysis: true
  suggested_next_agent: health_score

# ============
# health_score
# ============
health_score_handoff:
  agent: health_score
  analysis_type: system_health_check
  status: completed
  confidence: 0.94

  key_findings:
    - "Overall system health: 87% (GOOD)"
    - "Data quality: 92% (EXCELLENT)"
    - "Model performance: 85% (GOOD)"
    - "Latency: 98th percentile = 1.2s (GOOD)"
    - "Error rate: 0.3% (EXCELLENT)"

  outputs:
    health_metrics:
      overall_score: 0.87
      data_quality_score: 0.92
      model_performance_score: 0.85
      latency_score: 0.88
      reliability_score: 0.91

    component_health:
      - component: "data_pipeline"
        status: "healthy"
        score: 0.92

      - component: "ml_models"
        status: "healthy"
        score: 0.85

      - component: "api_endpoints"
        status: "healthy"
        score: 0.91

    alerts:
      - severity: "warning"
        component: "drift_monitor"
        message: "Data drift detected in call_frequency"

  requires_further_analysis: false
  suggested_next_agent: null

# ==============================================================================
# TIER 4: ML PREDICTIONS HANDOFFS
# ==============================================================================

# ============
# prediction_synthesizer
# ============
prediction_synthesizer_handoff:
  agent: prediction_synthesizer
  analysis_type: prediction_aggregation
  status: completed
  confidence: 0.86

  key_findings:
    - "3 models aggregated: conversion, churn, response"
    - "Ensemble prediction: 0.68 conversion probability"
    - "Confidence: HIGH (0.86)"
    - "Recommendation: ENGAGE this HCP"
    - "Expected ROI: 3.2x"

  outputs:
    predictions:
      conversion_probability: 0.68
      churn_probability: 0.15
      response_probability: 0.72

    ensemble_prediction:
      final_prediction: 0.68
      confidence: 0.86
      models_used: 3
      disagreement_score: 0.12

    recommendation:
      action: "engage"
      priority: "high"
      expected_roi: 3.2

    model_sources:
      - model_id: "conversion_model_v3"
        prediction: 0.70
        confidence: 0.85

      - model_id: "churn_model_v2"
        prediction: 0.15
        confidence: 0.90

  requires_further_analysis: false
  suggested_next_agent: explainer

# ============
# resource_optimizer
# ============
resource_optimizer_handoff:
  agent: resource_optimizer
  analysis_type: resource_allocation
  status: completed
  confidence: 0.83

  key_findings:
    - "Optimal allocation computed for 5 territories"
    - "Reallocate 15% of samples to high-ROI segments"
    - "Expected improvement: +12% efficiency"
    - "Resource constraints: SATISFIED"
    - "Budget utilization: 94%"

  outputs:
    allocations:
      territory_14:
        current_samples: 100
        optimal_samples: 125
        current_calls: 50
        optimal_calls: 55
        expected_improvement: 0.18

      territory_22:
        current_samples: 120
        optimal_samples: 110
        current_calls: 60
        optimal_calls: 58
        expected_improvement: 0.08

    constraints_satisfied: true
    total_budget_used: 0.94
    expected_overall_improvement: 0.12

  requires_further_analysis: false
  suggested_next_agent: null

# ==============================================================================
# TIER 5: SELF-IMPROVEMENT HANDOFFS
# ==============================================================================

# ============
# explainer
# ============
explainer_handoff:
  agent: explainer
  analysis_type: explanation
  status: completed
  confidence: 0.90

  key_findings:
    - "3 key insights extracted"
    - "Explanation adapted for analyst audience"
    - "5 follow-up questions generated"
    - "Visual suggestions: effect_plot, segment_comparison"
    - "Related analyses: 2 identified"

  outputs:
    executive_summary: "Enhanced targeting increased NRx by 18% (95% CI: 12-24%, p=0.003). Effect strongest in academic centers (+32%) and high-volume practices (+25%). Middle-decile HCPs in Midwest represent highest ROI opportunity (4.2x). Recommend prioritizing academic high-volume segment for maximum impact."

    detailed_explanation: "..."  # Full narrative

    extracted_insights:
      - insight_id: "1"
        category: "finding"
        statement: "Enhanced targeting causally increases NRx by 18%"
        confidence: 0.85
        actionability: "immediate"

      - insight_id: "2"
        category: "recommendation"
        statement: "Prioritize academic high-volume HCPs for maximum ROI"
        confidence: 0.82
        actionability: "short_term"

      - insight_id: "3"
        category: "opportunity"
        statement: "Midwest middle-decile HCPs offer 4.2x ROI potential"
        confidence: 0.79
        actionability: "short_term"

    visual_suggestions:
      - type: "effect_plot"
        title: "Causal Effect Estimate"
        description: "Bar chart showing ATE with 95% CI"

      - type: "segment_effects"
        title: "Treatment Effects by Segment"
        description: "Grouped bar chart showing CATE by segment"

    follow_up_questions:
      - "What's driving these effects at the segment level?"
      - "How do we prioritize these opportunities?"
      - "What resources are needed to implement?"

  requires_further_analysis: false
  suggested_next_agent: feedback_learner

# ============
# feedback_learner
# ============
feedback_learner_handoff:
  agent: feedback_learner
  analysis_type: feedback_learning
  status: completed
  confidence: 0.75

  key_findings:
    - "12 feedback examples processed"
    - "Positive feedback: 10 examples (83%)"
    - "Negative feedback: 2 examples (17%)"
    - "Pattern identified: Users prefer segment breakdowns"
    - "RAG weight adjustment: +0.05 for graph retrieval"

  outputs:
    feedback_summary:
      total_examples: 12
      positive_count: 10
      negative_count: 2
      satisfaction_rate: 0.83

    learned_patterns:
      - pattern_id: "pattern_001"
        description: "Users engage more with segment-level breakdowns"
        confidence: 0.78
        action: "Increase CATE analysis in responses"

      - pattern_id: "pattern_002"
        description: "Causal explanations valued over correlations"
        confidence: 0.82
        action: "Prioritize causal agents over exploratory"

    rag_adjustments:
      graph_retrieval_weight: 0.25  # Increased from 0.20
      dense_retrieval_weight: 0.48  # Decreased from 0.50
      sparse_retrieval_weight: 0.27  # Decreased from 0.30

  assumptions:
    - "Feedback is representative of user population"
    - "Recent feedback more relevant than old"

  limitations:
    - "Small sample size (n=12)"
    - "May overfit to recent user preferences"

  requires_further_analysis: false
  suggested_next_agent: null

# ==============================================================================
# VALIDATION SCHEMA (for automated testing)
# ==============================================================================

validation_schema:
  required_keys:
    - agent
    - analysis_type
    - status
    - confidence
    - key_findings

  type_checks:
    agent: string
    analysis_type: string
    status: string  # enum: [completed, partial, failed]
    confidence: float  # range: [0.0, 1.0]
    key_findings: array  # item_type: string

  array_constraints:
    key_findings:
      min_items: 1
      max_items: 5

  conditional_requirements:
    # If status is "completed", outputs must be present
    - if:
        status: completed
      then:
        required: [outputs]

    # If status is "failed", warnings should be present
    - if:
        status: failed
      then:
        required: [warnings]

# ==============================================================================
# USAGE EXAMPLES
# ==============================================================================

usage_example_sequential:
  description: "Sequential agent execution with handoffs"
  flow:
    - agent: causal_impact
      handoff: "causal_impact_handoff"
      next: gap_analyzer

    - agent: gap_analyzer
      receives: "causal_impact_handoff"
      handoff: "gap_analyzer_handoff"
      next: explainer

    - agent: explainer
      receives: ["causal_impact_handoff", "gap_analyzer_handoff"]
      handoff: "explainer_handoff"
      next: null  # terminal

usage_example_tier0_pipeline:
  description: "ML Foundation pipeline handoffs"
  flow:
    - agent: scope_definer
      handoff: "scope_definer_handoff"
      next: data_preparer

    - agent: data_preparer
      receives: "scope_definer_handoff"
      handoff: "data_preparer_handoff"
      gate: "QC_GATE"  # Blocks if QC fails
      next: model_selector

    - agent: model_trainer
      receives: "model_selector_handoff"
      handoff: "model_trainer_handoff"
      next: feature_analyzer

    - agent: feature_analyzer
      receives: "model_trainer_handoff"
      handoff: "feature_analyzer_handoff"
      next: model_deployer

# ==============================================================================
# END OF HANDOFF SPECIFICATION
# ==============================================================================
