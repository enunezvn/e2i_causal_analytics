"""Feature Analyzer Adapter

Bridges the feature_analyzer agent output with the FeatureStoreClient.
Registers generated/selected features in the feature store for:
- Version tracking
- Reuse across experiments
- Online serving
"""

import hashlib
import logging
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

import pandas as pd

from .client import FeatureStoreClient
from .models import Feature, FeatureGroup, FeatureValueType

logger = logging.getLogger(__name__)


# Feature type mapping
PYTHON_TO_FEATURE_TYPE = {
    "int64": FeatureValueType.INT64,
    "int32": FeatureValueType.INT64,
    "float64": FeatureValueType.FLOAT64,
    "float32": FeatureValueType.FLOAT64,
    "object": FeatureValueType.STRING,
    "bool": FeatureValueType.BOOL,
    "datetime64[ns]": FeatureValueType.TIMESTAMP,
}


class FeatureAnalyzerAdapter:
    """
    Adapter to register features from feature_analyzer to feature store.

    This class provides:
    - Automatic feature registration from analyzer output
    - Feature versioning based on generation config
    - Batch writing of feature values for training data
    - Feature group management for experiments

    Example:
        ```python
        from src.feature_store import FeatureStoreClient
        from src.feature_store.feature_analyzer_adapter import FeatureAnalyzerAdapter

        fs_client = FeatureStoreClient(...)
        adapter = FeatureAnalyzerAdapter(fs_client)

        # Register features from feature_analyzer state
        await adapter.register_features_from_state(
            state=analyzer_state,
            experiment_id="exp_001",
            entity_key="hcp_id",
        )
        ```
    """

    def __init__(
        self,
        feature_store_client: FeatureStoreClient,
        auto_create_groups: bool = True,
    ):
        """
        Initialize adapter.

        Args:
            feature_store_client: Initialized FeatureStoreClient instance
            auto_create_groups: Automatically create feature groups if not exist
        """
        self.fs_client = feature_store_client
        self.auto_create_groups = auto_create_groups

    async def register_features_from_state(
        self,
        state: Dict[str, Any],
        experiment_id: str,
        entity_key: str,
        owner: Optional[str] = None,
        tags: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        Register generated and selected features from feature_analyzer state.

        Args:
            state: Feature analyzer state containing:
                - generated_features: List of generated feature metadata
                - selected_features: List of selected feature names
                - feature_importance: Dict of feature importance scores
                - X_train_selected: DataFrame with selected features
            experiment_id: Experiment identifier for grouping
            entity_key: Primary entity key for features (e.g., "hcp_id")
            owner: Feature owner/team
            tags: Tags for organization

        Returns:
            Dict with registration results
        """
        results = {
            "feature_group_created": False,
            "features_registered": 0,
            "features_skipped": 0,
            "errors": [],
        }

        try:
            # Create feature group for this experiment
            group_name = f"feature_analyzer_{experiment_id}"
            feature_group = self._ensure_feature_group(
                name=group_name,
                description=f"Features generated by feature_analyzer for experiment {experiment_id}",
                owner=owner,
                tags=tags or ["feature_analyzer", "generated"],
            )

            if feature_group:
                results["feature_group_created"] = True

            # Get generated feature metadata
            generated_features = state.get("generated_features", [])
            selected_features = state.get("selected_features", [])
            feature_importance = state.get("feature_importance", {})

            # Get DataFrame for type inference
            X_selected = state.get("X_train_selected") or state.get("X_train")

            # Register each selected feature
            for feature_meta in generated_features:
                feature_name = feature_meta.get("name")
                if not feature_name:
                    continue

                # Skip if not in selected features
                if selected_features and feature_name not in selected_features:
                    results["features_skipped"] += 1
                    continue

                try:
                    # Determine value type
                    if X_selected is not None and feature_name in X_selected.columns:
                        dtype = str(X_selected[feature_name].dtype)
                        value_type = PYTHON_TO_FEATURE_TYPE.get(
                            dtype, FeatureValueType.STRING
                        )
                    else:
                        value_type = FeatureValueType.FLOAT64

                    # Build feature description
                    description_parts = []
                    if feature_meta.get("type"):
                        description_parts.append(f"Type: {feature_meta['type']}")
                    if feature_meta.get("transformation"):
                        description_parts.append(
                            f"Transformation: {feature_meta['transformation']}"
                        )
                    if feature_meta.get("source"):
                        description_parts.append(f"Source: {feature_meta['source']}")
                    if feature_meta.get("sources"):
                        description_parts.append(
                            f"Sources: {', '.join(feature_meta['sources'])}"
                        )

                    # Add importance score
                    importance = feature_importance.get(feature_name)
                    if importance:
                        description_parts.append(f"Importance: {importance:.4f}")

                    # Create feature
                    self.fs_client.create_feature(
                        feature_group_name=group_name,
                        name=feature_name,
                        value_type=value_type.value,
                        entity_keys=[entity_key],
                        description=" | ".join(description_parts) if description_parts else None,
                        owner=owner,
                        tags=[
                            feature_meta.get("type", "generated"),
                            feature_meta.get("transformation", "unknown"),
                        ],
                    )

                    results["features_registered"] += 1

                except Exception as e:
                    results["errors"].append({
                        "feature": feature_name,
                        "error": str(e),
                    })
                    logger.warning(f"Failed to register feature {feature_name}: {e}")

            logger.info(
                f"Registered {results['features_registered']} features "
                f"(skipped {results['features_skipped']}) for experiment {experiment_id}"
            )

            return results

        except Exception as e:
            logger.exception("Feature registration failed")
            results["errors"].append({"error": str(e)})
            return results

    async def write_training_features(
        self,
        state: Dict[str, Any],
        experiment_id: str,
        entity_key: str,
        entity_id_column: str,
        timestamp_column: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Write feature values from training data to feature store.

        This enables online serving of the same features used in training.

        Args:
            state: Feature analyzer state
            experiment_id: Experiment identifier
            entity_key: Entity key name (e.g., "hcp_id")
            entity_id_column: Column containing entity IDs
            timestamp_column: Column containing event timestamps (optional)

        Returns:
            Dict with write results
        """
        results = {
            "values_written": 0,
            "errors": [],
        }

        try:
            X_selected = state.get("X_train_selected")
            if X_selected is None:
                results["errors"].append("No training data in state")
                return results

            selected_features = state.get("selected_features", [])
            if not selected_features:
                selected_features = [c for c in X_selected.columns if c != entity_id_column]

            group_name = f"feature_analyzer_{experiment_id}"
            now = datetime.now(timezone.utc)

            # Prepare batch writes
            batch_values = []
            for _, row in X_selected.iterrows():
                entity_id = row.get(entity_id_column)
                if not entity_id:
                    continue

                timestamp = row.get(timestamp_column, now) if timestamp_column else now

                for feature_name in selected_features:
                    if feature_name in [entity_id_column, timestamp_column]:
                        continue

                    value = row.get(feature_name)
                    if pd.isna(value):
                        continue

                    batch_values.append({
                        "feature_name": feature_name,
                        "entity_values": {entity_key: str(entity_id)},
                        "value": value if not isinstance(value, (pd.Timestamp, datetime)) else value.isoformat(),
                        "event_timestamp": timestamp,
                        "feature_group": group_name,
                    })

            # Write in batches
            if batch_values:
                written = self.fs_client.write_batch_features(
                    feature_values=batch_values,
                    invalidate_cache=True,
                )
                results["values_written"] = written

            logger.info(f"Wrote {results['values_written']} feature values for experiment {experiment_id}")

        except Exception as e:
            logger.exception("Feature value writing failed")
            results["errors"].append(str(e))

        return results

    def _ensure_feature_group(
        self,
        name: str,
        description: Optional[str] = None,
        owner: Optional[str] = None,
        tags: Optional[List[str]] = None,
    ) -> Optional[FeatureGroup]:
        """
        Ensure feature group exists, create if not.

        Args:
            name: Feature group name
            description: Group description
            owner: Owner name
            tags: Tags

        Returns:
            FeatureGroup instance or None if creation disabled
        """
        # Check if exists
        existing = self.fs_client.get_feature_group(name)
        if existing:
            return existing

        # Create if auto-creation enabled
        if self.auto_create_groups:
            try:
                return self.fs_client.create_feature_group(
                    name=name,
                    description=description,
                    owner=owner,
                    tags=tags,
                )
            except Exception as e:
                logger.warning(f"Failed to create feature group {name}: {e}")
                return None

        return None

    def get_feature_version_hash(
        self,
        feature_config: Dict[str, Any],
        selected_features: List[str],
    ) -> str:
        """
        Generate a version hash for feature configuration.

        This enables tracking which feature configuration produced which features.

        Args:
            feature_config: Feature generation configuration
            selected_features: List of selected feature names

        Returns:
            Version hash string
        """
        # Create deterministic representation
        config_str = str(sorted(feature_config.items()))
        features_str = ",".join(sorted(selected_features))
        combined = f"{config_str}:{features_str}"

        return hashlib.md5(combined.encode()).hexdigest()[:8]


def get_feature_analyzer_adapter(
    feature_store_client: FeatureStoreClient,
) -> FeatureAnalyzerAdapter:
    """
    Factory function to create FeatureAnalyzerAdapter.

    Args:
        feature_store_client: Initialized FeatureStoreClient

    Returns:
        FeatureAnalyzerAdapter instance
    """
    return FeatureAnalyzerAdapter(feature_store_client)
